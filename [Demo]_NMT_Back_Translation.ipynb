{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tienhuynh96/Low_Resource_NMT/blob/main/%5BDemo%5D_NMT_Back_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Back-Translation\n",
        "- Train model translate Vietnames to English.\n",
        "- Synthetic Data (create more data):\n",
        "  + Use trainer (VI-EN) to create sample.\n",
        "  + Use Reference to create sample or batch sample.\n",
        "- Train model EN-VI include orginial data and created data"
      ],
      "metadata": {
        "id": "ZcL8pStRafq4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK2NmGWiaeFz"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers sentencepiece datasets accelerate evaluate sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2MhaFCJaeFz",
        "outputId": "0ad326bc-28e9-41a9-e505-57be83a15220"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/server-ailab-12gb/miniconda3/envs/thainq_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    MBart50TokenizerFast,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Vi-EN**"
      ],
      "metadata": {
        "id": "xtV3ojG9akKO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-jL7Yq-aeFz"
      },
      "outputs": [],
      "source": [
        "class NMTDataset(Dataset):\n",
        "    def __init__(self, cfg, data_type=\"train\"):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.src_texts, self.tgt_texts = self.read_data(data_type)\n",
        "\n",
        "        self.src_input_ids = self.texts_to_sequences(self.src_texts)\n",
        "        self.labels = self.texts_to_sequences(self.tgt_texts)\n",
        "\n",
        "    def read_data(self, data_type):\n",
        "        data = load_dataset(\n",
        "            \"mt_eng_vietnamese\",\n",
        "            \"iwslt2015-en-vi\",\n",
        "            split=data_type\n",
        "        )\n",
        "        src_texts = [sample[\"translation\"][self.cfg.src_lang] for sample in data]\n",
        "        tgt_texts = [sample[\"translation\"][self.cfg.tgt_lang] for sample in data]\n",
        "        return src_texts, tgt_texts\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        data_inputs = self.cfg.tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.cfg.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return data_inputs.input_ids\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.src_input_ids[idx],\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return np.shape(self.src_input_ids)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8z2KTeKaeFz"
      },
      "outputs": [],
      "source": [
        "class BaseConfig:\n",
        "    \"\"\" base Encoder Decoder config \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class NMTConfig(BaseConfig):\n",
        "    # Data\n",
        "    src_lang = 'vi'\n",
        "    tgt_lang = 'en'\n",
        "    max_len = 75\n",
        "    add_special_tokens = True\n",
        "\n",
        "    # Model\n",
        "    model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "    # Training\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    learning_rate = 5e-5\n",
        "    train_batch_size = 16\n",
        "    eval_batch_size = 16\n",
        "    num_train_epochs = 2\n",
        "    save_total_limit = 1\n",
        "    ckpt_dir = f'./mbart50-{src_lang}-{tgt_lang}'\n",
        "    eval_steps = 1000\n",
        "\n",
        "    # Inference\n",
        "    beam_size = 5\n",
        "\n",
        "cfg = NMTConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvSTrmv7aeFz"
      },
      "outputs": [],
      "source": [
        "# tokenizer = MBart50TokenizerFast.from_pretrained(cfg.model_name, src_lang=\"en_XX\",tgt_lang = \"vi_VN\")\n",
        "cfg.tokenizer = MBart50TokenizerFast.from_pretrained(cfg.model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(cfg.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byv6iSpGaeF0"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    preds= np.where(preds != -100, preds, cfg.tokenizer.pad_token_id)\n",
        "    decoded_preds = cfg.tokenizer.batch_decode(preds, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    labels= np.where(labels != -100, labels, cfg.tokenizer.pad_token_id)\n",
        "    decoded_labels = cfg.tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != cfg.tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMh9oxwaaeF0",
        "outputId": "f22609e8-6013-408a-b76b-2252e5d6c0f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset mt_eng_vietnamese (/home/server-ailab-12gb/.cache/huggingface/datasets/mt_eng_vietnamese/iwslt2015-en-vi/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71)\n",
            "Found cached dataset mt_eng_vietnamese (/home/server-ailab-12gb/.cache/huggingface/datasets/mt_eng_vietnamese/iwslt2015-en-vi/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71)\n",
            "Found cached dataset mt_eng_vietnamese (/home/server-ailab-12gb/.cache/huggingface/datasets/mt_eng_vietnamese/iwslt2015-en-vi/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = NMTDataset(cfg, data_type=\"train\")\n",
        "valid_dataset = NMTDataset(cfg, data_type=\"validation\")\n",
        "test_dataset = NMTDataset(cfg, data_type=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cXqhTneaeF0"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy='steps',\n",
        "    save_steps=cfg.eval_steps,\n",
        "    eval_steps=cfg.eval_steps,\n",
        "    output_dir=cfg.ckpt_dir,\n",
        "    per_device_train_batch_size=cfg.train_batch_size,\n",
        "    per_device_eval_batch_size=cfg.eval_batch_size,\n",
        "    learning_rate=cfg.learning_rate,\n",
        "    save_total_limit=cfg.save_total_limit,\n",
        "    num_train_epochs=cfg.num_train_epochs,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    cfg.tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=cfg.tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXFWhv1NaeF0",
        "outputId": "b613ec4a-d70d-45d4-9e44-4831a666aac2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/8334 [00:00<?, ?it/s]You're using a MBart50TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "  6%|▌         | 500/8334 [05:45<1:24:48,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6006, 'learning_rate': 4.700023998080154e-05, 'epoch': 0.12}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 1000/8334 [11:10<1:19:31,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3267, 'learning_rate': 4.4000479961603073e-05, 'epoch': 0.24}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 12%|█▏        | 1000/8334 [12:36<1:19:31,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4115850627422333, 'eval_bleu': 35.2226, 'eval_gen_len': 30.632, 'eval_runtime': 85.9398, 'eval_samples_per_second': 14.766, 'eval_steps_per_second': 0.465, 'epoch': 0.24}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 1500/8334 [18:30<1:18:43,  1.45it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3224, 'learning_rate': 4.100071994240461e-05, 'epoch': 0.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 2000/8334 [24:15<1:14:02,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3238, 'learning_rate': 3.8000959923206145e-05, 'epoch': 0.48}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 24%|██▍       | 2000/8334 [25:40<1:14:02,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.40333837270736694, 'eval_bleu': 36.3721, 'eval_gen_len': 30.2963, 'eval_runtime': 85.3961, 'eval_samples_per_second': 14.86, 'eval_steps_per_second': 0.468, 'epoch': 0.48}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 2500/8334 [31:11<1:03:20,  1.53it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3192, 'learning_rate': 3.500119990400768e-05, 'epoch': 0.6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 3000/8334 [36:37<57:53,  1.54it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3138, 'learning_rate': 3.2001439884809216e-05, 'epoch': 0.72}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            " 36%|███▌      | 3000/8334 [37:58<57:53,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.39890530705451965, 'eval_bleu': 36.0185, 'eval_gen_len': 30.591, 'eval_runtime': 81.1346, 'eval_samples_per_second': 15.641, 'eval_steps_per_second': 0.493, 'epoch': 0.72}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 3500/8334 [43:30<52:32,  1.53it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3121, 'learning_rate': 2.9001679865610755e-05, 'epoch': 0.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 4000/8334 [49:16<50:08,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3062, 'learning_rate': 2.6001919846412287e-05, 'epoch': 0.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            " 48%|████▊     | 4000/8334 [50:47<50:08,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3957849442958832, 'eval_bleu': 37.5987, 'eval_gen_len': 30.0969, 'eval_runtime': 91.6207, 'eval_samples_per_second': 13.851, 'eval_steps_per_second': 0.437, 'epoch': 0.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 4500/8334 [56:21<41:35,  1.54it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2427, 'learning_rate': 2.3002159827213822e-05, 'epoch': 1.08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 5000/8334 [1:01:46<36:08,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.217, 'learning_rate': 2.000239980801536e-05, 'epoch': 1.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 60%|█████▉    | 5000/8334 [1:03:07<36:08,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4291688799858093, 'eval_bleu': 36.1415, 'eval_gen_len': 30.2734, 'eval_runtime': 80.4327, 'eval_samples_per_second': 15.777, 'eval_steps_per_second': 0.497, 'epoch': 1.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 5500/8334 [1:08:39<30:44,  1.54it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2182, 'learning_rate': 1.7002639788816897e-05, 'epoch': 1.32}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 6000/8334 [1:14:04<25:18,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2142, 'learning_rate': 1.4002879769618432e-05, 'epoch': 1.44}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 72%|███████▏  | 6000/8334 [1:15:26<25:18,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.42046114802360535, 'eval_bleu': 36.0593, 'eval_gen_len': 30.5122, 'eval_runtime': 81.5502, 'eval_samples_per_second': 15.561, 'eval_steps_per_second': 0.49, 'epoch': 1.44}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 6500/8334 [1:20:57<19:54,  1.54it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2167, 'learning_rate': 1.1003119750419968e-05, 'epoch': 1.56}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 7000/8334 [1:26:23<14:30,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2119, 'learning_rate': 8.003359731221503e-06, 'epoch': 1.68}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 84%|████████▍ | 7000/8334 [1:27:44<14:30,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.41834622621536255, 'eval_bleu': 36.3178, 'eval_gen_len': 30.316, 'eval_runtime': 81.2804, 'eval_samples_per_second': 15.613, 'eval_steps_per_second': 0.492, 'epoch': 1.68}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 7500/8334 [1:33:16<09:02,  1.54it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2103, 'learning_rate': 5.003599712023038e-06, 'epoch': 1.8}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 8000/8334 [1:38:46<03:52,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2099, 'learning_rate': 2.003839692824574e-06, 'epoch': 1.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 96%|█████████▌| 8000/8334 [1:40:16<03:52,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4232094883918762, 'eval_bleu': 35.9713, 'eval_gen_len': 30.5201, 'eval_runtime': 90.3194, 'eval_samples_per_second': 14.05, 'eval_steps_per_second': 0.443, 'epoch': 1.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8334/8334 [1:44:22<00:00,  1.75it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 6262.0212, 'train_samples_per_second': 42.58, 'train_steps_per_second': 1.331, 'train_loss': 0.28221002299064124, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8334/8334 [1:44:22<00:00,  1.33it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8334, training_loss=0.28221002299064124, metrics={'train_runtime': 6262.0212, 'train_samples_per_second': 42.58, 'train_steps_per_second': 1.331, 'train_loss': 0.28221002299064124, 'epoch': 2.0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tp2SlXeAaeF0",
        "outputId": "97ef506d-780a-441c-c6da-2e64f9bbc444"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a MBart50TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100%|██████████| 40/40 [01:28<00:00,  2.21s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[     2, 250004,  14847, ...,      1,      1,      1],\n",
              "       [     2, 250004,     87, ...,      1,      1,      1],\n",
              "       [     2, 250004,    360, ...,      1,      1,      1],\n",
              "       ...,\n",
              "       [     2, 250004,     87, ...,      1,      1,      1],\n",
              "       [     2, 250004,  25689, ...,      1,      1,      1],\n",
              "       [     2, 250004,      2, ...,      1,      1,      1]]), label_ids=array([[250004,  14847,     87, ...,      1,      1,      1],\n",
              "       [250004,   3493,     87, ...,      1,      1,      1],\n",
              "       [250004,    360,  10696, ...,      1,      1,      1],\n",
              "       ...,\n",
              "       [250004,     87,  15673, ...,      1,      1,      1],\n",
              "       [250004,  25689,    398, ...,      1,      1,      1],\n",
              "       [250004,      2,      1, ...,      1,      1,      1]]), metrics={'test_loss': 0.3957849442958832, 'test_bleu': 37.5987, 'test_gen_len': 30.0969, 'test_runtime': 90.3645, 'test_samples_per_second': 14.043, 'test_steps_per_second': 0.443})"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_prediction = trainer.predict(test_dataset)\n",
        "test_prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Synthetic Data**"
      ],
      "metadata": {
        "id": "w5OMZQNAasbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vi Monolingual Data: https://drive.google.com/drive/folders/1brbflvjGcF7GqDQFxafUbGcbf68jCB0g?usp=sharing"
      ],
      "metadata": {
        "id": "WpwAZdFPcU1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Cach 1: Su dung trainer => tạo dataset**"
      ],
      "metadata": {
        "id": "-mDSeSK2bLI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_x6CWYzaeF0"
      },
      "outputs": [],
      "source": [
        "class PhoNMTDataset(Dataset):\n",
        "    def __init__(self, cfg, src_texts, tgt_texts):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.src_texts, self.tgt_texts = src_texts, tgt_texts\n",
        "\n",
        "        self.src_input_ids = self.texts_to_sequences(self.src_texts)\n",
        "        self.labels = self.texts_to_sequences(self.tgt_texts)\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        data_inputs = self.cfg.tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.cfg.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return data_inputs.input_ids\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.src_input_ids[idx],\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return np.shape(self.src_input_ids)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlhX8XxtaeF0"
      },
      "outputs": [],
      "source": [
        "with open('./test.vi', 'r') as f:\n",
        "    vi_phomt = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_QN3lkwaeF0",
        "outputId": "9e44b32e-c128-436a-9fed-547715d46b13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Anh Albert Barnett và chị Susan Barnett , thuộc hội thánh West ở Tuscaloosa , Alabama\\n',\n",
              " 'Ngày 11 và 12-1-2020 , những cơn bão lớn đã quét qua và phá huỷ nhiều vùng ở miền nam và miền trung Hoa Kỳ .\\n',\n",
              " 'Những trận mưa to và gió lớn trong suốt hai ngày cùng với nhiều cơn lốc xoáy đã gây thiệt hại nặng nề cho nhiều bang .\\n',\n",
              " 'Đáng buồn là anh Albert Barnett 85 tuổi , và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ .\\n',\n",
              " 'Chi nhánh Hoa Kỳ cũng cho biết có ít nhất bốn căn nhà của anh em chúng tôi và hai Phòng Nước Trời bị hư hại nhẹ .\\n']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vi_phomt[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t1hcjsKaeF0",
        "outputId": "59680ae7-cf21-40de-b592-16cbc6ee9a18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19151"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vi_phomt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gBKwChJaeF0"
      },
      "outputs": [],
      "source": [
        "phomt_dataset = PhoNMTDataset(cfg, vi_phomt, vi_phomt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8hzPajfaeF0",
        "outputId": "7ccecc0e-1fd2-4af2-daff-505c13afbbca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a MBart50TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100%|██████████| 1197/1197 [19:37<00:00,  1.02it/s]\n"
          ]
        }
      ],
      "source": [
        "pred = trainer.predict(phomt_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wlxGfKuaeF0",
        "outputId": "1457aa1d-22e2-4332-8bb4-a80e22f402ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[     2, 250004,  24748, ...,      1,      1,      1],\n",
              "       [     2, 250004,   2161, ...,      1,      1,      1],\n",
              "       [     2, 250004,    581, ...,      1,      1,      1],\n",
              "       ...,\n",
              "       [     2, 250004,    360, ...,      1,      1,      1],\n",
              "       [     2, 250004,   3164, ...,      1,      1,      1],\n",
              "       [     2, 250004,  48176, ...,      1,      1,      1]]), label_ids=array([[250004,  67921,  24748, ...,      1,      1,      1],\n",
              "       [250004,  48752,     13, ...,      1,      1,      1],\n",
              "       [250004,  32964,  13312, ...,      1,      1,      1],\n",
              "       ...,\n",
              "       [250004,    360,  15824, ...,      1,      1,      1],\n",
              "       [250004,  64511,  13909, ...,      1,      1,      1],\n",
              "       [250004,     44,  83425, ...,      1,      1,      1]]), metrics={'test_loss': 0.6733054518699646, 'test_bleu': 24.9305, 'test_gen_len': 24.3073, 'test_runtime': 1178.7906, 'test_samples_per_second': 16.246, 'test_steps_per_second': 1.015})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvW2_emcaeF0"
      },
      "outputs": [],
      "source": [
        "en_phomt_preds = cfg.tokenizer.batch_decode(pred.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-vyk7BbaeF0",
        "outputId": "b2a6399b-609e-4160-9f35-600235fabed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Albert Barnett and his sister Susan Barnett, from the West Church in Tuscaloosa, Alabama.',\n",
              " 'On November 11 and 12, 2020, major storms swept through and destroyed parts of the south and central United States.',\n",
              " 'The heavy rains and winds over the course of two days, coupled with the heavy storm surge, caused extensive damage in many states.',\n",
              " 'Sadly, Albert Barnett was 85, and his wife Susan Barnett was 75 when a tornado struck their home.',\n",
              " 'The U.S. branch also reported that at least four of our brother &apos;s homes and two of our guest houses suffered minor damage.',\n",
              " 'Also, storms can devastate a brother &apos;s business.',\n",
              " 'Local elders and survivors are helping and providing material and spiritual support to those affected by the disaster.',\n",
              " 'We believe that our heavenly Father, Jesus Christ, is comforting our brothers and sisters in their grief.',\n",
              " 'International agencies and government officials have spoken out in response to the ruling of the Russian Supreme Court banning the worship of the Russian Virgin Mary.',\n",
              " 'Critics of Russia &apos;s harsh and unfair state practices targeting a small religious group known for its benign actions.']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_phomt_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmkPMy6raeF0",
        "outputId": "ef730b7b-5f66-4fa0-dbbe-86ed0e248be0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Anh Albert Barnett và chị Susan Barnett , thuộc hội thánh West ở Tuscaloosa , Alabama\\n',\n",
              " 'Ngày 11 và 12-1-2020 , những cơn bão lớn đã quét qua và phá huỷ nhiều vùng ở miền nam và miền trung Hoa Kỳ .\\n',\n",
              " 'Những trận mưa to và gió lớn trong suốt hai ngày cùng với nhiều cơn lốc xoáy đã gây thiệt hại nặng nề cho nhiều bang .\\n',\n",
              " 'Đáng buồn là anh Albert Barnett 85 tuổi , và vợ anh là chị Susan Barnett 75 tuổi đã thiệt mạng do một cơn lốc xoáy quét qua nhà họ .\\n',\n",
              " 'Chi nhánh Hoa Kỳ cũng cho biết có ít nhất bốn căn nhà của anh em chúng tôi và hai Phòng Nước Trời bị hư hại nhẹ .\\n',\n",
              " 'Ngoài ra , những cơn bão cũng gây hư hại lớn cho cơ sở kinh doanh của một anh em .\\n',\n",
              " 'Các trưởng lão địa phương và giám thị xung quanh đang giúp đỡ và cung cấp về vật chất và tinh thần cho các anh chị bị ảnh hưởng trong thảm hoạ này .\\n',\n",
              " 'Chúng ta tin chắc rằng Cha trên trời , Đức Giê-hô-va , đang an ủi những anh chị em của chúng ta trong cảnh đau buồn .\\n',\n",
              " 'Các cơ quan và viên chức chính phủ quốc tế đã lên tiếng trước phán quyết của Toà Tối Cao Nga về việc cấm sự thờ phượng của Nhân Chứng Giê-hô-va ở Nga .\\n',\n",
              " 'Các lời nhận xét chỉ trích nước Nga có hành động tư pháp khắc nghiệt và bất công nhắm vào một nhóm tôn giáo nhỏ được biết đến là hoạt động một cách ôn hoà .\\n']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vi_phomt[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cach 2: Sinh theo sample hoặc theo batch**"
      ],
      "metadata": {
        "id": "Exh9LB3LbN32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(\n",
        "    text,\n",
        "    tokenizer,\n",
        "    model,\n",
        "    device=\"cpu\",\n",
        "    max_length=75,\n",
        "    beam_size=5\n",
        "    ):\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "        )\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        early_stopping=True,\n",
        "        num_beams=beam_size,\n",
        "        length_penalty=2.0\n",
        "    )\n",
        "\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    return output_str[0]\n",
        "\n",
        "en_phomt_preds = []\n",
        "for sent in vi_phomt:\n",
        "    en_sent = inference(sent, cfg.tokenizer, model)\n",
        "    en_phomt_preds.append(en_sent)"
      ],
      "metadata": {
        "id": "e_eCww2rbdc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**En-VI**"
      ],
      "metadata": {
        "id": "k7svhMMUbiV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add created data above to dataset"
      ],
      "metadata": {
        "id": "SeAbIpzygsAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XfNemv7aeF1"
      },
      "outputs": [],
      "source": [
        "class NMTDataset(Dataset):\n",
        "    def __init__(self, cfg, src_augs=[], tgt_augs=[], data_type=\"train\"):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.src_texts, self.tgt_texts = self.read_data(data_type)\n",
        "        if data_type == 'train':\n",
        "            self.src_texts.extend(src_augs)\n",
        "            self.tgt_texts.extend(tgt_augs)\n",
        "\n",
        "        self.src_input_ids = self.texts_to_sequences(self.src_texts)\n",
        "        self.labels = self.texts_to_sequences(self.tgt_texts)\n",
        "\n",
        "    def read_data(self, data_type):\n",
        "        data = load_dataset(\n",
        "            \"mt_eng_vietnamese\",\n",
        "            \"iwslt2015-en-vi\",\n",
        "            split=data_type\n",
        "        )\n",
        "        src_texts = [sample[\"translation\"][self.cfg.src_lang] for sample in data]\n",
        "        tgt_texts = [sample[\"translation\"][self.cfg.tgt_lang] for sample in data]\n",
        "        return src_texts, tgt_texts\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        data_inputs = self.cfg.tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.cfg.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return data_inputs.input_ids\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.src_input_ids[idx],\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return np.shape(self.src_input_ids)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRY3zNx_aeF1"
      },
      "outputs": [],
      "source": [
        "class BaseConfig:\n",
        "    \"\"\" base Encoder Decoder config \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class NMTConfig(BaseConfig):\n",
        "    # Data\n",
        "    src_lang = 'en'\n",
        "    tgt_lang = 'vi'\n",
        "    max_len = 75\n",
        "    add_special_tokens = True\n",
        "\n",
        "    # Model\n",
        "    model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "    # Training\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    learning_rate = 5e-5\n",
        "    train_batch_size = 32\n",
        "    eval_batch_size = 32\n",
        "    num_train_epochs = 2\n",
        "    save_total_limit = 1\n",
        "    ckpt_dir = f'./mbart50-{src_lang}-{tgt_lang}-backtranslation-2'\n",
        "    eval_steps = 1000\n",
        "\n",
        "    # Inference\n",
        "    beam_size = 5\n",
        "\n",
        "cfg = NMTConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vch1GWwRaeF1"
      },
      "outputs": [],
      "source": [
        "# tokenizer = MBart50TokenizerFast.from_pretrained(cfg.model_name, src_lang=\"en_XX\",tgt_lang = \"vi_VN\")\n",
        "cfg.tokenizer = MBart50TokenizerFast.from_pretrained(cfg.model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(cfg.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urrT2g4qaeF1",
        "outputId": "123ba26e-0c78-40d4-b1a4-7a481a3f2466"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset mt_eng_vietnamese (/home/server-ailab-12gb/.cache/huggingface/datasets/mt_eng_vietnamese/iwslt2015-en-vi/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71)\n",
            "Found cached dataset mt_eng_vietnamese (/home/server-ailab-12gb/.cache/huggingface/datasets/mt_eng_vietnamese/iwslt2015-en-vi/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71)\n",
            "Found cached dataset mt_eng_vietnamese (/home/server-ailab-12gb/.cache/huggingface/datasets/mt_eng_vietnamese/iwslt2015-en-vi/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = NMTDataset(cfg, en_phomt_preds, vi_phomt, data_type=\"train\")\n",
        "valid_dataset = NMTDataset(cfg, data_type=\"validation\")\n",
        "test_dataset = NMTDataset(cfg, data_type=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFCIHa0HaeF1",
        "outputId": "3e2b711a-b532-40aa-c828-05b13585a6ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "152469"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd_Dr0j4aeF1"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    preds= np.where(preds != -100, preds, cfg.tokenizer.pad_token_id)\n",
        "    decoded_preds = cfg.tokenizer.batch_decode(preds, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    labels= np.where(labels != -100, labels, cfg.tokenizer.pad_token_id)\n",
        "    decoded_labels = cfg.tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != cfg.tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFk2GqQIaeF1"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy='steps',\n",
        "    save_steps=cfg.eval_steps,\n",
        "    eval_steps=cfg.eval_steps,\n",
        "    output_dir=cfg.ckpt_dir,\n",
        "    per_device_train_batch_size=cfg.train_batch_size,\n",
        "    per_device_eval_batch_size=cfg.eval_batch_size,\n",
        "    learning_rate=cfg.learning_rate,\n",
        "    save_total_limit=cfg.save_total_limit,\n",
        "    num_train_epochs=cfg.num_train_epochs,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    cfg.tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=cfg.tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8T5Dl2VaeF1",
        "outputId": "469aa1c2-6cc0-4879-ed15-888a97a74c15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9530 [00:00<?, ?it/s]You're using a MBart50TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "  5%|▌         | 500/9530 [05:45<1:42:47,  1.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7768, 'learning_rate': 4.737670514165792e-05, 'epoch': 0.1}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1000/9530 [11:24<1:38:14,  1.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4776, 'learning_rate': 4.475341028331584e-05, 'epoch': 0.21}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 10%|█         | 1000/9530 [13:02<1:38:14,  1.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.568303108215332, 'eval_bleu': 32.9774, 'eval_gen_len': 32.948, 'eval_runtime': 97.3289, 'eval_samples_per_second': 13.038, 'eval_steps_per_second': 0.411, 'epoch': 0.21}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 1500/9530 [18:55<1:26:51,  1.54it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.473, 'learning_rate': 4.213011542497377e-05, 'epoch': 0.31}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 2000/9530 [24:20<1:21:28,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4677, 'learning_rate': 3.950682056663169e-05, 'epoch': 0.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 21%|██        | 2000/9530 [25:45<1:21:28,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5526649951934814, 'eval_bleu': 33.5444, 'eval_gen_len': 32.6872, 'eval_runtime': 85.5442, 'eval_samples_per_second': 14.834, 'eval_steps_per_second': 0.468, 'epoch': 0.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 2500/9530 [31:15<1:15:57,  1.54it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4618, 'learning_rate': 3.688352570828961e-05, 'epoch': 0.52}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███▏      | 3000/9530 [36:40<1:10:35,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4611, 'learning_rate': 3.4260230849947537e-05, 'epoch': 0.63}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 31%|███▏      | 3000/9530 [38:02<1:10:35,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.540764570236206, 'eval_bleu': 33.9756, 'eval_gen_len': 32.6391, 'eval_runtime': 82.5237, 'eval_samples_per_second': 15.377, 'eval_steps_per_second': 0.485, 'epoch': 0.63}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 3500/9530 [43:33<1:06:43,  1.51it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4518, 'learning_rate': 3.163693599160546e-05, 'epoch': 0.73}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 4000/9530 [48:58<59:49,  1.54it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4515, 'learning_rate': 2.901364113326338e-05, 'epoch': 0.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \n",
            " 42%|████▏     | 4000/9530 [50:22<59:49,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5334458947181702, 'eval_bleu': 34.1069, 'eval_gen_len': 32.9582, 'eval_runtime': 84.4311, 'eval_samples_per_second': 15.03, 'eval_steps_per_second': 0.474, 'epoch': 0.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 4500/9530 [55:53<54:25,  1.54it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4487, 'learning_rate': 2.63903462749213e-05, 'epoch': 0.94}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 5000/9530 [1:01:17<49:01,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4043, 'learning_rate': 2.3767051416579224e-05, 'epoch': 1.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 52%|█████▏    | 5000/9530 [1:02:41<49:01,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5374477505683899, 'eval_bleu': 34.2478, 'eval_gen_len': 32.6856, 'eval_runtime': 83.8705, 'eval_samples_per_second': 15.13, 'eval_steps_per_second': 0.477, 'epoch': 1.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 5500/9530 [1:08:12<43:36,  1.54it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.363, 'learning_rate': 2.1143756558237147e-05, 'epoch': 1.15}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 6000/9530 [1:13:37<38:12,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3635, 'learning_rate': 1.852046169989507e-05, 'epoch': 1.26}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 63%|██████▎   | 6000/9530 [1:15:00<38:12,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5342561602592468, 'eval_bleu': 34.3835, 'eval_gen_len': 32.7597, 'eval_runtime': 83.6559, 'eval_samples_per_second': 15.169, 'eval_steps_per_second': 0.478, 'epoch': 1.26}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 6500/9530 [1:20:31<32:45,  1.54it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3669, 'learning_rate': 1.589716684155299e-05, 'epoch': 1.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 7000/9530 [1:25:55<28:26,  1.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3625, 'learning_rate': 1.3273871983210914e-05, 'epoch': 1.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 73%|███████▎  | 7000/9530 [1:27:24<28:26,  1.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5296697020530701, 'eval_bleu': 34.4664, 'eval_gen_len': 32.8731, 'eval_runtime': 88.0977, 'eval_samples_per_second': 14.404, 'eval_steps_per_second': 0.454, 'epoch': 1.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 7500/9530 [1:33:15<21:55,  1.54it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3614, 'learning_rate': 1.0650577124868834e-05, 'epoch': 1.57}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 8000/9530 [1:38:40<16:31,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3565, 'learning_rate': 8.027282266526758e-06, 'epoch': 1.68}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 84%|████████▍ | 8000/9530 [1:40:03<16:31,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5277815461158752, 'eval_bleu': 34.7893, 'eval_gen_len': 32.6509, 'eval_runtime': 83.923, 'eval_samples_per_second': 15.121, 'eval_steps_per_second': 0.477, 'epoch': 1.68}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 8500/9530 [1:45:49<11:54,  1.44it/s]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3587, 'learning_rate': 5.403987408184681e-06, 'epoch': 1.78}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 9000/9530 [1:51:36<06:08,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3518, 'learning_rate': 2.7806925498426024e-06, 'epoch': 1.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \n",
            " 94%|█████████▍| 9000/9530 [1:53:10<06:08,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5230357646942139, 'eval_bleu': 35.2273, 'eval_gen_len': 32.7801, 'eval_runtime': 93.7786, 'eval_samples_per_second': 13.532, 'eval_steps_per_second': 0.427, 'epoch': 1.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 9500/9530 [1:59:04<00:20,  1.45it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3538, 'learning_rate': 1.5739769150052467e-07, 'epoch': 1.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9530/9530 [1:59:26<00:00,  1.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 7166.4681, 'train_samples_per_second': 42.551, 'train_steps_per_second': 1.33, 'train_loss': 0.426721374435665, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9530/9530 [1:59:26<00:00,  1.33it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9530, training_loss=0.426721374435665, metrics={'train_runtime': 7166.4681, 'train_samples_per_second': 42.551, 'train_steps_per_second': 1.33, 'train_loss': 0.426721374435665, 'epoch': 2.0})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQLmlRhMaeF1",
        "outputId": "115fb6d2-fb06-4151-8d71-9b4b8b666fb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [01:31<00:00,  2.29s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5230357646942139,\n",
              " 'eval_bleu': 35.2273,\n",
              " 'eval_gen_len': 32.7801,\n",
              " 'eval_runtime': 93.6366,\n",
              " 'eval_samples_per_second': 13.552,\n",
              " 'eval_steps_per_second': 0.427,\n",
              " 'epoch': 2.0}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Checkpoint**\n",
        "https://drive.google.com/drive/folders/1ii_lPm2-1CfIhQM8RVzLgTHMxXDKgnk4?usp=sharing"
      ],
      "metadata": {
        "id": "lLf_JqXQceZV"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "thainq_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}